{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to Acquire:\n",
    "# 1. overview of electric cars currently on the market from ev-database.org\n",
    "# 2. Average car prices for consumers since 1960 (real and nominal)\n",
    "# 3. US median wage since 1960 (real and nominal)\n",
    "# 4. EV battery prices since 2013, can also be component prices (Li, Cobalt, Nickel, Aluminum)\n",
    "# 5. EVs produced yearly since 2013\n",
    "# 6. EVs sold yearly 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: imports\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Always Check for the Hidden API When Web Scraping - Youtube Video by John Watson Rooney\n",
    "\n",
    "### Using REI's site as an example, under section camp electronics\n",
    "\n",
    "# 1. navigate to site, inspect page elements\n",
    "# 2. in the inspect page elemnets box, click the network tab in the toolbar at top, and check the box for 'Fetch/XHR' to retrieve the full web request\n",
    "# 3. navigate to the bottom of the target page, click on 'more' or 'page 2', which will generate more search results\n",
    "# 4. select the request that contains all of the web page info (page size/items). This result is the body of the scrpaing file we will build.\n",
    "# 5. Copy the appropriate result with a right click \"copy cURL\"\n",
    "# 6. Paste into Insomnia (API tool), and attempt to edit the item counts per page, to reduce aggregate page requests during scraping.\n",
    "# 7. Once complete with parameter adjustment, click the drop down arrow to the right of the GET request, select 'generate code'\n",
    "# 8. Select 'Python', copy to clipboard, paste in IDE\n",
    "# 9. Note: common issues with generated dict:\n",
    "#     a. quotes: 2x double quotes. fix by replacing the outer double quotes with single quotes\n",
    "#     b. clean up the code by removing the empty payload varaible, then from the response variable equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n     \\nCompare electric vehicles - EV Database'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the basics, set up a get(url), check response\n",
    "url = \"https://ev-database.org/#sort:path~type~order=.rank~number~desc|range-slider-range:prev~next=0~1200|range-slider-acceleration:prev~next=2~23|range-slider-topspeed:prev~next=110~450|range-slider-battery:prev~next=10~200|range-slider-towweight:prev~next=0~2500|range-slider-fastcharge:prev~next=0~1500|paging:currentPage=0|paging:number=9\"\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
    "response = requests.get(url, headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "soup.text[:50]\n",
    "# functions check complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"title\" href=\"/car/1708/MG-MG4-Electric-Long-Range\"><span class=\"mg\">MG</span> <span class=\"model\">MG4 Electric Long Range</span></a>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functions check\n",
    "url = \"https://ev-database.org/#sort:path~type~order=.rank~number~desc|range-slider-range:prev~next=0~1200|range-slider-acceleration:prev~next=2~23|range-slider-topspeed:prev~next=110~450|range-slider-battery:prev~next=10~200|range-slider-towweight:prev~next=0~2500|range-slider-fastcharge:prev~next=0~1500|paging:currentPage=0|paging:number=all\"\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "soup.find_all('a', class_='title')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MG MG4 Electric Long Range\n",
      "Battery Electric Vehicle\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "testlink = 'https://ev-database.org/car/1708/MG-MG4-Electric-Long-Range'\n",
    "\n",
    "r = requests.get(testlink, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "title = soup.find(class_='sub-header').text\n",
    "\n",
    "ev_range = soup.find('div', class_='in-line block', attrs='table')\n",
    "\n",
    "print(title)\n",
    "print(ev_range)\n",
    "\n",
    "#print(title.replace(\"Battery Electric Vehicle\",''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeEVs(n):\n",
    "\n",
    "    baseurl = 'https://ev-database.org'\n",
    "    \n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
    "\n",
    "    evlinks = []\n",
    "\n",
    "    for x in range(1,n):\n",
    "\n",
    "        r = requests.get(f'https://ev-database.org/#sort:path~type~order=.rank~number~desc|range-slider-range:prev~next=0~1200|range-slider-acceleration:prev~next=2~23|range-slider-topspeed:prev~next=110~450|range-slider-battery:prev~next=10~200|range-slider-towweight:prev~next=0~2500|range-slider-fastcharge:prev~next=0~1500|paging:currentPage={x}|paging:number=36')\n",
    "\n",
    "        soup = BeautifulSoup(r.content, 'lxml')\n",
    "        #make sure this primary list is correctly accessed, b/c the secondary for loop will access the list child\n",
    "        evlist = soup.find_all('div', class_='title-wrap')\n",
    "\n",
    "        for ev in evlist:\n",
    "            for link in ev.find_all('a', href=True):\n",
    "                evlinks.append(baseurl + link['href'])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #following line commented out for scrapes only 1 page in length\n",
    "    #print(f\"\\rFetching page {page} of {n-1} at {url}, time per query is {time_taken}\", end=\"\")\n",
    "\n",
    "    # soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # make = [make.text for make in soup.find_all(class_=\"title\")]\n",
    "    # model = [model.text for model in soup.find_all(class_=\"title\")]\n",
    "    # accel = [accel.text for accel in soup.find_all(class_=\"acceleration\")]\n",
    "    # speed = [speed.text for speed in soup.find_all(class_=\"topspeed\")]\n",
    "    # ev_range = [ev_range.text for ev_range in soup.find_all(class_=\"erange_real\")]\n",
    "    # bev = [bev.text for bev in soup.find_all(class_=\"battery\")]\n",
    "    # charge = [charge.text for charge in soup.find_all(class_=\"fastcharge_speed_print\")]\n",
    "    # g_price = [g_price.text for g_price in soup.find_all(title=\"Price in Germany before incentives\")]\n",
    "    # d_price = [d_price.text for d_price in soup.find_all(title=\"Price in The Netherlands before incentives\")]\n",
    "    # uk_price = [uk_price.text for uk_price in soup.find_all(title=\"Price in the United Kingdom after incentives\")]\n",
    "\n",
    "    # evFacts = {'Make': make,\n",
    "    #         'Model': model,\n",
    "    #         '0_t0_100': accel,\n",
    "    #         'Top_Speed': speed,\n",
    "    #         'Range': ev_range,\n",
    "    #         'Battery_Capacity': bev,\n",
    "    #         'Fast_Charge': charge,\n",
    "    #         'German_Price': g_price,\n",
    "    #         'Dutch_Price': d_price,\n",
    "    #         'UK_Price': uk_price}\n",
    "    \n",
    "    # results = results + evFacts\n",
    "    # # use lists instead, then manually create the df columns\n",
    "    # results_df = pd.DataFrame(results)\n",
    "    # #results_df.to_csv('REIscrape.csv')\n",
    "    # return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I need to clean and transform this data\n",
    "# step 1: seperate the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrapeWhiskey(n):\n",
    "\n",
    "    baseurl = 'https://www.thewhiskyexchange.com/'\n",
    "\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
    "\n",
    "    productlinks = []\n",
    "    \n",
    "    for x in range(1,n):\n",
    "\n",
    "        r = requests.get(f'https://www.thewhiskyexchange.com/c/35/japanese-whisky?pg={x}')\n",
    "\n",
    "        soup = BeautifulSoup(r.content, 'lxml')\n",
    "\n",
    "        productlist = soup.find_all('li', class_=\"product-grid__item\")\n",
    "\n",
    "        for item in productlist:\n",
    "            for link in item.find_all('a', href=True):\n",
    "                productlinks.append(baseurl + link['href'])\n",
    "    \n",
    "    print(len(productlist), len(productlinks))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 52\n"
     ]
    }
   ],
   "source": [
    "scrapeWhiskey(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
